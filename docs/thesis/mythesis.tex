\documentclass[letterpaper,12pt,onecolumn,final]{report}

\pdftrailerid{}
\pdfsuppressptexinfo15
\pdfminorversion=4

%% MANDATORY PACKAGES
\usepackage{cuthesis}         % Concordia's thesis style
\usepackage[english]{babel}   % load english localization
\usepackage{type1ec}          % type 1 font
\usepackage[T1]{fontenc}      % correct some font representation, needs cm-super fonts
\usepackage{times}            % use Times New Roman font
\usepackage[titletoc,title]{appendix}     % include Appendix command, add to ToC
\usepackage{setspace}         % control double/single line spacing

%% OPTIONAL PACKAGES
%\counterwithout{footnote}{chapter}        % do no reset footnote # between chapters
\usepackage[hyphens]{url}     % print links
\usepackage{hyperref}         % provides hyperlinks (text different than link)
%\usepackage[hyphenbreaks]{breakurl}       % break long URL after hyphens
\hypersetup{
	colorlinks=true,
	breaklinks=true,
	linkcolor=black,
	citecolor=black,
	urlcolor=black,
	filecolor=black,
	linktoc=all,
}
\usepackage{graphicx}
%\graphicspath{{img/}}

\usepackage{blindtext}

%% CUSTOM MACROS
%\newcommand{\tickyes}{{\small\checkmark}}
%\newcommand{\tickno}{{\small$\times$}}

%% CUSTOM COMMANDS
%\newcommand{\subhead}[1]{\noindent{\textbf{#1.}}}

%% THESIS SETTINGS
\author{Mosabbir Khan Shiblu}
\title{Refactoring Detection in JavaScript}

% As of 2019, title is no longer used...
%\titleOfPhDAuthor{Mr.}         % or Ms., Mrs., Miss, etc. (only for PhD's)

% if PhD, uncomment:
%\PhD
% else if Master's, uncomment:
\mastersDegree{Master of Computer Science}
\program{Computer Science}
\dept{The Department\\of\\Computer Science and Software Engineering}

%% See current GPD at https://www.concordia.ca/admissions/graduate/programs/contacts.html
\GpdOrChairOfDept{Dr.\ 	LEILA KOSSEIM}
\isGpd % Chair by default
%% See current Dean at  https://www.concordia.ca/ginacody/about/leadership/office-dean/dean-of-engineering-and-computer-science.html
\deanOfENCS{Dr.\ Mourad Debbabi } 
\chairOfCommittee{Dr.\ Chair}
\examinerExternal{Dr.\ External}
\examinerFirst{Dr.\ Examiner1}
\examinerSecond{Dr.\ Examiner2}
\examinerExternalToProgram{Dr.\ ExternalToProgram}
\supervisor{Dr.\ Nikolaos Tsantalis}
%% Following two lines are required if you have a co-supervisor
%\hasCosupervisor
%\coSupervisor{Dr.\ Co-supervisor}

%% Comment to use current month, needs to match initial submission
\submitmonth{November}
\submityear{2021}
%% Comment if date of defence is unknown yet, fill for final submission
\defencedate{December 7, 2021}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\doublespacing
\begin{document}

\begin{abstract}
{%trick to force double spacing in the abstract, otherwise some paragraphs may show single spaced
\setstretch{1.6667}
%\blindtext[1]
TODO Para1

%\blindtext[1]
TODO Para2

%\blindtext[1]

TODO Para3

%\blindtext[1] 
TODO Para4
}
\end{abstract}

%\doublespacing
\begin{acknowledgments}

% keep this section even if empty
	%\blindtext[2]
I would like to express my gratitude and thanks to my supervisor, Dr. Nikolaos Tsantalis. His invaluable guidance
and continuous opened a new horizon of knowledge to me.

I would also like to thank my colleagues, Mohammad Sadegh Aalizadeh, Mehran Jodavi, and Ameya Ketkar who shared their best experiences and were amazing in teamwork and helped me to learn a lot in my journey at Concordia.

Thank you.

Mosabbir Khan Shiblu
	
\end{acknowledgments}


%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
% suggestion of intro

TODO %~\cite{cold-boot-attack}.

\section{Motivation}
%\blindtext[5]
TODO

\section{Thesis Statement}
%\blindtext[2]
TODO

\section{Objectives and Contributions}
%\blindtext[3]
TODO

\section{Outline}
The rest of the thesis is organized as follows...


%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Wok}
\label{chap:background}

In this section, we talk about several research areas and and tools that are related to refactorings particularly focusing on their detection methodology.

Leo Brodie \cite{thinkingforth} first mentioned the word “Refactoring” in his book “Thinking Forth”, originally published in 1984. In addition to describing refactoring techniques, the author also discussed many software development principles and practices. 

Over the past few decades, various techniques for detecting refactoring activities have been proposed, implemented, and validated.

\section{Refactoring Detection Approach}
\subsection{Detection Using Meta Data}
\subsection{Detection by Static Source Code Analysis}
Demeyer et al. \cite{Demeyer2000} introduced the first strategy for identifying the refactored elements between two system snapshots. They defined four heuristics based on the changes of object-oriented source code metrics such as method size, class size, number of inherited or overwritten methods to identify refactorings of three general categories (Split/Merge Class, Move Method, and Split Method). For example, to detect Extract Superclass refactoring, they start by inspecting the increase in the inheritance hierarchy of a class to detect newly added classes. Then they observed whether the number of methods and fields in the hierarchy has been decreased but increased in the newly added class. To validate their technique, they applied it on different versions of three software systems. However, the precision of their approach was seemingly on the lower side, for example, for Move Method refactorings (limited to super, sub, and sibling classes) the reported average precision was 23\%. One of the reasons for low accuracy is due to the partial overlapping of heuristics causing some false negative refactorings to be reported as false positives for other refactorings. On the other hand, the paper concluded that from the perspective of reverse engineering, the proposed heuristics were extremely useful to uncover where, how, and maybe why implementation had drifted from its original design.

Antoniol et al. \cite{Antoniol2004} used an automatic technique based on Vector Space cosine similarity to compare identifiers in different classes in order to detect the renaming and splitting of classes. Since it's based on a similarity threshold, it does not perform very well for classes with many changes and may require threshold adjustment on a case basis.

Weißgerber and Diehl \cite{Weissgerber2006} developed the first technique for identifying class-level/locally-scoped refactorings i.e refactorings that occur within one class, and thus, within the same file (e.g. Rename Method). Their approach first extracts and identifies added and deleted refactoring candidates (fields, methods, and classes) by parsing deltas and then comparing each pair's name similarity from a version control system. For ambiguous candidate pairs, it uses a clone detection tool CCFINDER \cite{Kamiya2002} to compare their bodies and then rank them. CCFINDER is also configured to ignore whitespaces/comments and to match consistently renamed variables, method names, and references to members. Finally, they used random sampling to estimate the precision whereas commit messages were inspected manually to find documented refactorings in order to compute the recall. Although they have achieved a good recall of 89\%, it has been proven that commit messages are not reliable indicators of refactoring activity \cite{Krasniqi2020}, \cite{MurphyHill2012}. Lastly, the authors stated that their technique is susceptible to multiple refactorings performed on the same entity.

Dig et al. \cite{Dig2006} developed an Eclipse plug-in named REFACTORINGCRAWLER which initially uses a computationally inexpensive text-based similarity metric - Shingles encoding \cite{Broder1997} to find possible refactoring candidates. Shingles act as "fingerprints" for texts (e.g. method bodies) and reduce the ramification of small textual changes like renaming and minor edits. This enables REFACTORINGCRAWLER to detect similar pairs of high-level code elements (methods, classes, and packages) between two versions of a project much more robustly than existing string matching techniques that are vulnerable to minor changes. To detect actual refactorings, it then refines the candidates by employing a more expensive and precise semantic analysis based on reference graphs. To evaluate the performance of REFACTORINGCRAWLER, it was applied on three open-source Java projects and archived high values for both precision(95\%) and recall(90\%). However, similar to the work of Weißgerber and Diehl \cite{Weissgerber2006} the authors manually discovered the applied refactorings by inspecting their commits/ release notes for computing recall while they inspected the source code to compute precision. Later, Biegel et al. \cite{Biegel2011} replicated Weißgerber’s approach using three different similarity metrics: CCFinder (text-based), JCCD \cite{Biegel2010} (ast-based), and Shingles (token-based). It was concluded that the three metrics performed with a comparable quality even though they can affect the ranking of refactoring candidates.


Xing and Stroulia \cite{Xing2006} used both textual and structural similarity to detect refactorings between two versions of a system in their Eclipse plug-in named JDEVAN \cite{Xing2007} \cite{Xing2008}. JDEVAN initially constructs two UML logical design models from the source code corresponding to two versions of a Java system.  Next, using UMLDiff \cite{Xing2005}, the two models are compared and the differences between them are reported as removal, addition, moving, and renaming of UML entities (e.g. class, package). Finally, JDEVAN’s refactoring-detection module defines a suite of queries \cite{Xing2006} assisted by a set of similarity metrics that attempt to categorize detected differences as refactoring instances through a hierarchical pairwise comparison between the two models' packages, classes, methods, and fields. As an example of an implemented query, an \textit{Extract Operation} refactoring is inferred when the set of usage relations (read, write, call, instantiate) inside a newly added method proved to be a subset of the removed usage relations from the original method or their intersection set is greater than a user-specific threshold.  JDEVAN found all the documented refactorings when applied on two systems and proved to be useful in detecting different types of refactorings in several studies. However, the authors confirmed that its rename and move refactorings detection is vulnerable to cases where there are not enough relations between the refactored entities and other parts of the program.

REF-FINDER \cite{Kim2010} by Pete et al. \cite{Prete2010} is capable of detecting 63 of Fowlers' catalog \cite{Fowler1999} of 72 refactoring types which contains the most comprehensive list of refactoring types to date. It first describes classes, methods, and fields as a set of logic predicates along with their content (e.g. method body) and structural dependencies (i.e. field access, method calls, subtyping, and overriding) to represent the versions of a program as a database of logic facts. Additionally, supported refactorings are encoded as logic rules where the antecedent defines the constraints (i.e. changefacts) and the consequent holds the refactoring type to be inferred. Next, it converts the antecedent of these logic rules as logic queries and then invokes them against the database of logic facts to identify program differences that match the constraints of each refactoring type under focus. Besides, by tracking the dependencies among refactoring types, lower-level refactorings were queried to identify higher-level, composite refactorings making Ref-Finder the first tool capable of detecting composite refactorings where each refactoring consists of a set of atomic refactorings. For example, Extract Superclass refactoring is inferred by checking if a new superclass is created and a number of PullUp Method/Field refactorings were identified that had moved fields and methods to the newly created class. For the detection of some types of refactoring, their rules require a special logic predicate that indicates if the word-level similarity between two candidate methods is above a threshold. This was implemented as a block-level clone detection technique that trims parenthesis and removes escape characters, returns keywords, and computes the world-level similarity between the two code fragments using the longest common subsequence algorithm. The tool was tested on three open-source Java programs and precision of 95\% and recall of 79\% were reported. However, later studies reported lower precision and recall for Ref-Finder \cite{Soares2013} \cite{Silva2017} \cite{Tan2019}. Considering refactorings applied on isolation (root canal refactorings \cite{MurphyHill2012}) and ignoring refactorings with overlapping changes (i.e. floss refactorings \cite{MurphyHill2012}) was the reason behind higher precision and recall in the evaluation conducted by the authors.

Tsantalis et al. \cite{Tsantalis2013} proposed a tool based on an extended, lightweight variation of the UMLDiff \cite{Xing2005} which is an algorithm for differencing object-oriented models. It is capable of identifying 14 high-level refactoring types: Rename Package/Class/Method, Move Class/Method/Field, Pull Up Method/Field, Push Down Method/-Field, Extract Method, Inline Method, and Extract Superclass/Interface. The process identifies refactorings between two models in several rounds. First, it compares the names or signatures of classes, methods, and fields in a top-down fashion and determines whether they have been matched, removed from the first model, or added to the second model. Next, removed elements are compared against the added elements by the equality of their names and parameter count to identify the changes in signatures of fields and methods. Third, the leftover removed/added classes are matched based on the similarity of signatures of members from the previous step thus this step can endure type changes. Finally, a set of refactoring detection rules defined by Biegel et al. \cite{Biegel2001} was extended and employed to infer actual refactoring instances. To evaluate their approach, the authors applied their technique in the version histories of three projects and reported 96.4\% precision for Extract Method refactoring with 8 false positives and 97.6\% precision for Rename Class refactoring with 4 false-positive instances. No false positives were found for the remaining refactorings. Later, Silva et al. \cite{Silva2016} extended and re-introduced the tool as Refactoring Miner and used it to mine refactorings on large scale in git repositories. In their evaluation of the tool, a precision of 63\% with 1,030 false positives out of 2,441 refactorings was reported. On the other hand, Refactoring Miner achieved precision and recall of 93\% and 98\% respectively when the authors evaluated it as a benchmark on the dataset created by Chaparro et al. \cite{Chaparro2014}.

In their tool REFDIFF, Silva and Valente \cite{Silva2017} introduced the concept of analyzing only the changed, added, or deleted files between two versions of a program to detect refactorings. Its is capable of detecting 13 high-level refactoring types through static analysis and code similarity comparison. As a first step, Ref Diff represents the body of classes and methods as a multiset (or bag) of tokens whereas for each field it considers tokens of all the statements that use that field. Next, to find similarity between code entities, a variation of the TF-IDF weighting scheme \cite{Salton1986} is used to assign more weight to tokens that are less frequent, and thus have finer distinctive importance than other tokens. Additionally, the similarity threshold for different kinds of code elements is calibrated by using a set of ten commits from ten different open-source projects for which the project developers themselves have confirmed the applied refactorings \cite{Silva2016}. Finally, similar to the evaluation performed by Perte et al. \cite{Prete2010}, they evaluated REFDIFF based on an oracle of root canal refactorings applied by graduate students in 20 open-source projects. The evaluation suggested that REFDIFF surpassed RMiner \cite{Silva2016}, RefactoringCrawler \cite{Dig2006} and Ref-Finder \cite{Prete2010} in terms of performance and accuracy.

Later, Tsantalis et al. \cite{Tsantalis2018} proposed a major evolution of their existing RefactoringMiner tool and renamed it to RMiner (RefactoringMiner version 1.0) which is the first refactoring detection tool that does not rely on code similarity thresholds. Similar to REFDIFF, RMiner also processes only the change, added, or deleted files of a commit however, unlike its competitors such as REFDIFF, REF-FINDER, UMLDIFF, and REFACTORINGCRAWLER; RMiner can tolerate unparseable programs. Consequently, this technique can achieve better accuracy and efficiency by decreasing the number of incorrect code entity matches as the majority of the change history of software systems cannot be successfully compiled \cite{Tufano2017}. RMiner employs an AST-based statement matching algorithm and a set of detection rules to detect 15 representative refactoring types. It matches statements in a round-based fashion where textually identical statements are matched first. Then, the algorithm employs two novel techniques: abstraction, to facilitate the matching of statements having a different AST node type and argumentation, which deals with changes in sub-expressions within statements due to the replacement of expression with method parameters, and vice-versa. To deal with overlapping refactorings (e.g. variable renames), while matching two statements, RMiner performs a syntax-aware replacement of the compatible AST nodes to make them identical. For evaluation, the authors created a dataset with 3,188 real refactorings instances from 185 open-source Java projects. Using this oracle, the authors reported a precision of 98\% and recall of 87\%, which was the best result so far, surpassing RefDiff \cite{Silva2017}, the previous state-of-the-art, which achieved a precision of 75.7\% and a recall of 85.8\% in this dataset. The superiority of RMiner is also confirmed by Tan and Bockisch \cite{Tan2019} where it emerges as the winner among its competitors: RefactoringCrawler \cite{Dig2006}, Ref-Finder \cite{Prete2010} and RefDiff \cite{Silva2017}.

In continuation to their previous work, Silva et al. \cite{Silva2020} upgraded REFDIFF \cite{Silva2017} and represented as REFDIFF 2.0 which is the first multi-language refactoring detection tool. The tool is capable of detecting refactorings in Java, C and JavaScript programs and remains the only known tool capable of detecting performed refactorings in JavaScript. It employs a two phase approach where in the first phase source codes are represented as Code Structure Tree (CST) that abstracts away the detail of particular language. Each node in CST is represented by higher level entities such as classes, functions etc. Since code can be written outside of a class in JavaScript and C, file is also considered as a CST node. In the second phase, REFDIFF 2.0, uses the same approach of its predecessor and determines the similarity between the CST nodes by tokenizing the body of CST nodes and then computing their weight using a variation of TF-IDF weighting scheme. However, in contrast to its predecessor, REFDIFF 2.0 uses a single default similarity threshold of 0.5 for all kinds of code element relationships. For Java projects, REFDIFF 2.0, was evaluated on the same oracle \cite{Tsantalis2018} that was used to evaluate RMiner \cite{Tsantalis2018} and a precision of 96\% and a recall of 80\% were reported. Precision and recall for JavaScript and C projects ranged between 88\% to 91\% computed from small scale experiments.

\subsection{Real-time Detection}
Murphy-Hill et al. \cite{MurphyHill2012} tracked the usage history of refactoring commands available in Eclipse IDE using a plugin and found that developers had performed about 90\% of their refactorings manually instead of opting for the refactoring tool. Additionally, they often interleave refactorings with other behavior-modifying programming activities. Furthermore, developers rarely explicitly report their refactoring activities in commit messages.

Negara et al. \cite{Negara2013} developed CODINGTRACKER which infers refactorings from continuous code changes with the help of a refactoring inference plugin. Using their tool, they constructed a large corpus of 5,371 refactoring instances performed by 23 developers working on their IDEs. Their approach reported precision and recall of 93\% and 100\% respectively for a sample of both manually and automatically performed refactorings.

Similar to CODINGTRACKER \cite{Negara2013}, GHOSTFACTOR \cite{Ge2014} and REVIEWFACTOR \cite{Ge2017} infer fully completed refactorings by monitoring the fine-grained code changes in real-time inside the IDE. On the other hand BENEFACTOR \cite{Ge2012} and WITCHDOCTOR \cite{Foster2012} offer code completion by detecting ongoing manual refactorings.


%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Then}


%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and future work}
\label{chap:conclusion}

TODO
%\blindtext[5]

%This text requires a citation \cite{thinkingforth} \cite{MurphyHill2009} to embed the citation in the required position in the text.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}  %  Add Bibliography to TOC
\singlespacing % save space in the bibliography
\bibliographystyle{abbrv}
\bibliography{references}



%%%%%%%%%% Appendices %%%%%%%%%%%%%%%%
% ---- Appendix settings. Please Do NOT change them. -----
\appendix
\setcounter{table}{0}		% reset the table counter
\setcounter{figure}{0}		% reset the figure counter
\renewcommand{\thefigure}{\Alph{chapter}.\arabic{figure}} 	% numbering the a figure in Appendix as Figure A.2, Figure B.1, etc.
\renewcommand{\thetable}{\Alph{chapter}.\arabic{table}}		% numbering the a table in Appendix as Table A.2, Table B.1, etc.

%%%%%%%%%% Body of Appendix %%%%%%%%%%%%%%%%
\begin{appendices}
\doublespacing

\chapter{First Appendix}
\label{chap:apdx1}

\blindmathpaper

\chapter{Concordia Logos}
\label{chap:logos}
\begin{figure}[h!]
	\centering
	\includegraphics{logos/Concordia_University_logo}
	\caption{Concordia University}
\end{figure}
\vspace{2em}
\begin{figure}[h!]
	\centering
	\includegraphics{logos/Concordia_GinaCody_vertical}
	\caption{Gina Cody School of Engineering and Computer Science (vertical)}
\end{figure}
\vspace{2em}
\begin{figure}[h!]
	\centering
	\includegraphics{logos/Concordia_GinaCody_horizontal}
	\caption{Gina Cody School of Engineering and Computer Science (horizontal)}
\end{figure}

\end{appendices}

\end{document}