% Encoding: UTF-8
@Book{thinkingforth,
author = "Leo Brodie",
title = "Thinking Forth",
publisher = "Punchy Publishing",
year = 2004,
}

@Conference{MurphyHill2009,
  author    = {Emerson Murphy-Hill and Chris Parnin and Andrew P. Black},
  booktitle = {Proceedings of the 31st International Conference on Software Engineering},
  title     = {How we refactor, and how we know it},
  year      = {2009},
  address   = {New York, NY, USA},
  month     = {5},
  pages     = {287–297},
  publisher = {Association for Computing Machinery},
  series    = {ICSE '09},
  abstract  = {Much of what we know about how programmers refactor in the wild is based on studies
that examine just a few software projects. Researchers have rarely taken the time
to replicate these studies in other contexts or to examine the assumptions on which
they are based. To help put refactoring research on a sound scientific basis, we draw
conclusions using four data sets spanning more than 13 000 developers, 240 000 tool-assisted
refactorings, 2500 developer hours, and 3400 version control commits. Using these
data, we cast doubt on several previously stated assumptions about how programmers
refactor, while validating others. For example, we find that programmers frequently
do not indicate refactoring activity in commit logs, which contradicts assumptions
made by several previous researchers. In contrast, we were able to confirm the assumption
that programmers do frequently intersperse refactoring with other program changes.
By confirming assumptions and replicating studies made by other researchers, we can
have greater confidence that those researchers' conclusions are generalizable.},
  day       = {16},
  doi       = {10.1109/ICSE.2009.5070529},
  isbn      = {9781424434534},
  pagetotal = {11},
  url       = {https://doi.org/10.1109/ICSE.2009.5070529},
}

@inproceedings{Negara2013,
author = {Negara, Stas and Chen, Nicholas and Vakilian, Mohsen and Johnson, Ralph and Dig, Danny},
year = {2013},
month = {07},
pages = {552-576},
title = {A Comparative Study of Manual and Automated Refactorings},
volume = {7920},
doi = {10.1007/978-3-642-39038-8_23}
}

@article{Ge2012,
author = {Ge, Xi and DuBose, Quinton and Murphy-Hill, Emerson},
year = {2012},
month = {06},
pages = {211-221},
title = {Reconciling manual and automatic refactoring},
journal = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227192}
}

@Conference{Foster2012,
  author    = {Stephen R. Foster and William G. Griswold and Sorin Lerner},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering},
  title     = {WitchDoctor: IDE support for real-time auto-completion of refactorings},
  year      = {2012},
  address   = {Zurich, Switzerland},
  month     = {6},
  pages     = {222–232},
  publisher = {IEEE Press},
  series    = {ICSE '12},
  abstract  = {Integrated Development Environments (IDEs) have come to perform a wide variety of
tasks on behalf of the programmer, refactoring being a classic example. These operations
have undeniable benefits, yet their large (and growing) number poses a cognitive scalability
problem. Our main contribution is WitchDoctor -- a system that can detect, on the
fly, when a programmer is hand-coding a refactoring. The system can then complete
the refactoring in the background and propose it to the user long before the user
can complete it. This implies a number of technical challenges. The algorithm must
be 1) highly efficient, 2) handle unparseable programs, 3) tolerate the variety of
ways programmers may perform a given refactoring, 4) use the IDE's proven and familiar
refactoring engine to perform the refactoring, even though the the refactoring has
already begun, and 5) support the wide range of refactorings present in modern IDEs.
Our techniques for overcoming these challenges are the technical contributions of
this paper. We evaluate WitchDoctor's design and implementation by simulating over
5,000 refactoring operations across three open-source projects. The simulated user
is faster and more efficient than an average human user, yet WitchDoctor can detect
more than 90% of refactoring operations as they are being performed -- and can complete
over a third of refactorings before the simulated user does. All the while, WitchDoctor
remains robust in the face of non-parseable programs and unpredictable refactoring
scenarios. We also show that WitchDoctor is efficient enough to perform computation
on a keystroke-by-keystroke basis, adding an average overhead of only 15 milliseconds
per keystroke.},
  day       = {2},
  isbn      = {9781467310673},
  pagetotal = {11},
}

@Conference{Ge2014,
  author    = {Xi Ge and Emerson Murphy-Hill},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  title     = {Manual refactoring changes with automated refactoring validation},
  year      = {2014},
  address   = {New York, NY, USA},
  month     = {5},
  pages     = {1095–1105},
  publisher = {Association for Computing Machinery},
  series    = {ICSE 2014},
  abstract  = {Refactoring, the practice of applying behavior-preserving changes to existing code,
can enhance the quality of software systems. Refactoring tools can automatically perform
and check the correctness of refactorings. However, even when developers have these
tools, they still perform about 90% of refactorings manually, which is error-prone.
To address this problem, we propose a technique called GhostFactor separating transformation
and correctness checking: we allow the developer to transform code manually, but check
the correctness of her transformation automatically. We implemented our technique
as a Visual Studio plugin, then evaluated it with a human study of eight software
developers; GhostFactor improved the correctness of manual refactorings by 67%.},
  day       = {31},
  doi       = {10.1145/2568225.2568280},
  isbn      = {9781450327565},
  keywords  = {IDE, Refactoring, Restructuring, Tool},
  location  = {Hyderabad, India},
  pagetotal = {11},
  url       = {https://doi.org/10.1145/2568225.2568280},
}

@INPROCEEDINGS{Ge2017,  author={Ge, Xi and Sarkar, Saurabh and Witschey, Jim and Murphy-Hill, Emerson},  booktitle={2017 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},   title={Refactoring-aware code review},   year={2017},  volume={},  number={},  pages={71-79},  doi={10.1109/VLHCC.2017.8103453}}

@Conference{Demeyer2000,
  author    = {Serge Demeyer and Stéphane Ducasse and Oscar Nierstrasz},
  booktitle = {Proceedings of the 15th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
  title     = {Finding refactorings via change metrics},
  year      = {2000},
  address   = {New York, NY, USA},
  month     = {10},
  pages     = {166–177},
  publisher = {Association for Computing Machinery},
  series    = {OOPSLA '00},
  abstract  = {Reverse engineering is the process of uncovering the design and the design rationale
from a functioning software system. Reverse engineering is an integral part of any
successful software system, because changing requirements lead to implementations
that drift from their original design. In contrast to traditional reverse engineering
techniques ---which analyse a single snapshot of a system--- we focus the reverse
engineering effort by determining where the implementation has changed. Since changes
of object-oriented software are often phrased in terms of refactorings, we propose
a set of heuristics for detecting refactorings by applying lightweight, object-oriented
metrics to successive versions of a software system. We validate our approach with
three separate case studies of mature object-oriented software systems for which multiple
versions are available. The case studies suggest that the heuristics support the reverse
engineering process by focusing attention on the relevant parts of a software system.},
  day       = {1},
  doi       = {10.1145/353171.353183},
  isbn      = {158113200X},
  keywords  = {metrics, object-oriented frameworks, refactoring, reverse engineering, software evolution},
  location  = {Minneapolis, Minnesota, USA},
  pagetotal = {12},
  url       = {https://doi.org/10.1145/353171.353183},
}

@INPROCEEDINGS{Antoniol2004,  author={Antoniol, G. and Di Penta, M. and Merlo, E.},  booktitle={Proceedings. 7th International Workshop on Principles of Software Evolution, 2004.},   title={An automatic approach to identify class evolution discontinuities},   year={2004},  volume={},  number={},  pages={31-40},  doi={10.1109/IWPSE.2004.1334766}}

@INPROCEEDINGS{Weissgerber2006,  author={Weissgerber, Peter and Diehl, Stephan},  booktitle={21st IEEE/ACM International Conference on Automated Software Engineering (ASE'06)},   title={Identifying Refactorings from Source-Code Changes},   year={2006},  volume={},  number={},  pages={231-240},  doi={10.1109/ASE.2006.41}}

@article{Kamiya2002,
author = {Kamiya, Toshihiro and Kusumoto, Shinji and Inoue, Katsuro},
title = {CCFinder: A Multilinguistic Token-Based Code Clone Detection System for Large Scale Source Code},
year = {2002},
issue_date = {July 2002},
publisher = {IEEE Press},
volume = {28},
number = {7},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2002.1019480},
doi = {10.1109/TSE.2002.1019480},
abstract = {A code clone is a code portion in source files that is identical or similar to another.
Since code clones are believed to reduce the maintainability of software, several
code clone detection techniques and tools have been proposed. This paper proposes
a new clone detection technique, which consists of the transformation of input source
text and a token-by-token comparison. For its implementation with several useful optimization
techniques, we have developed a tool, named CCFinder, which extracts code clones in
C, C++, Java, COBOL, and other source files. As well, metrics for the code clones
have been developed: In order to evaluate the usefulness of CCFinder and metrics,
we conducted several case studies where we applied the new tool to the source code
of JDK, FreeBSD, NetBSD, Linux, and many other systems. As a result, CCFinder has
effectively found clones and the metrics have been able to effectively identify the
characteristics of the systems. In addition, we have compared the proposed technique
with other clone detection techniques.},
journal = {IEEE Trans. Softw. Eng.},
month = jul,
pages = {654–670},
numpages = {17},
keywords = {code clone, duplicated code, CASE tool, maintenance, metrics}
}
@Comment{jabref-meta: databaseType:bibtex;}